after the changes you mentioned 
import json
import google.generativeai as genai
from dotenv import load_dotenv
import os
from collections import defaultdict
import re
import streamlit as st
from ats import is_valid_date,_tracker
load_dotenv()

# Load environment variables from the .env file
API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=API_KEY)

model = genai.GenerativeModel("gemini-1.5-flash")

def resume_details(resume_text):
    prompt = f"""
    You are a resume parsing assistant. Given the following resume text, extract the following details in a structured JSON format:

    - Name
    - Email
    - Phone_1
    - Address (Precise with city)
    - GitHub: Extract profile URL (look for patterns like github.com/username)"
    - LinkedIn: Extract profile URL (look for linkedin.com/in/ patterns)"
    - Professional_Experience_in_Years
    - Highest_Education
    - Skills
    - Applied_for_Profile (given in the resume or based on certifications, education, and skills)
    - Education (Include these EXACT field names):
        - University
        - Degree
        - Graduation_Date (use format 'Month YYYY' like 'May 2023')
    - Work_Experience (Include these fields):
        - Job_Title
        - Company
        - Start_Date (format: 'Month YYYY')
        - End_Date (format: 'Month YYYY' or 'Present')
        - Projects:
            - Project_Title
            - Description
    - Certifications

    - Achievements (List of notable achievements)

    - Suggested_Resume_Category (infer the most relevant job category based on skills, certifications, and work experience; do not use 'N/A')
    - Recommended_Additional_Skills (provide 3-5 concrete skills relevant to the Suggested_Resume_Category; do not use 'N/A')
    The resume text:
    {resume_text}

    Return the information in a clean and readable JSON format. Ensure all fields are included. For Suggested_Resume_Category and Recommended_Additional_Skills, infer values if not explicitly stated—avoid 'N/A'.
    """
    response = model.generate_content(prompt).text
    response_api = response.replace("```json", "").replace("```", "").strip()

    # Convert 'None' to 'N/A' in the response
    response_api = response_api.replace('"None"', '"N/A"').replace("'None'", "'N/A'")

    try:
        parsed_data = json.loads(response_api)
        required_top_level_fields = {
            "Name": "N/A",
            "Email": "N/A",
            "Phone_1": "N/A",
            "Address": "N/A",
            "LinkedIn": "N/A",
            "GitHub": "N/A",  
            "Professional_Experience_in_Years": "N/A",
            "Highest_Education": "N/A",
            "Skills": [],
            "Applied_for_Profile": "N/A",
            "Education": [],
            "Work_Experience": [],
            "Certifications": [],
            "Suggested_Resume_Category": "N/A",
            "Achievements": [],
            "Recommended_Additional_Skills": []
        }

        # Set defaults for missing fields
        for field, default in required_top_level_fields.items():
            parsed_data.setdefault(field, default)

        # Ensure Certifications is a list
# Ensure Certifications is a list and replace any invalid entries with "N/A"
        parsed_data.setdefault("Certifications", [])
        if not isinstance(parsed_data["Certifications"], list):
            parsed_data["Certifications"] = [parsed_data["Certifications"]]
        parsed_data["Certifications"] = [
            c if c not in [None, "None", "", "N/A"] else "N/A"
            for c in parsed_data["Certifications"]
        ]
        if not parsed_data["Certifications"]:
            parsed_data["Certifications"] = ["N/A"]

        for edu in parsed_data.get("Education", []):
            edu.setdefault("Graduation_Date", "N/A")
            current_date = edu["Graduation_Date"]
            if not is_valid_date(current_date):
                edu["Graduation_Date"] = "N/A"
        # Inside resume_details()
        for job in parsed_data.get("Work_Experience", []):
            job.setdefault("Start_Date", "N/A")
            job.setdefault("End_Date", "N/A")
            job.setdefault("Projects", [])  # Force initialize Projects field

            # Ensure each project has Title and Description
            for project in job.get("Projects", []):
                project.setdefault("Project_Title", "N/A")
                project.setdefault("Description", "N/A")

        # Ensure Recommended_Additional_Skills is a list
        if not isinstance(parsed_data.get("Recommended_Additional_Skills", []), list):
            parsed_data["Recommended_Additional_Skills"] = []

        # Convert 'None' to 'N/A'
        def convert_none(obj):
            if isinstance(obj, dict):
                return {k: convert_none(v) for k, v in obj.items()}
            if isinstance(obj, list):
                return [convert_none(item) for item in obj]
            return obj if obj not in [None, "None"] else "N/A"
        
        parsed_data = convert_none(parsed_data)

        return parsed_data
    except json.JSONDecodeError as e:
        st.error(f"Error decoding JSON: {e}")
        return None
    
def count_na(parsed_data):
    missing_fields = [] 
    _tracker(parsed_data, missing_fields)
    return len(missing_fields), missing_fields 

            

def display_in_container(title, value):
    if not value or (isinstance(value, list) and not value):
        value = "N/A"
    elif isinstance(value, list):
        value = f"<ul>{''.join([f'<li>{item}</li>' for item in value])}</ul>" if len(value) > 1 else value[0]
    else:
        value = str(value)  # Convert non-string values to string


    st.markdown(f"""
    <div style="margin-bottom: 2px;">
        <strong style="font-size: 14px; color: #1d3557; display: block;">{title}</strong>
        <div style="border: 2px solid #457b9d; border-radius: 10px; padding: 13px; background-color: #E5FBF6FF; 
        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2);">
            {value}
        </div>
    </div>
    """, unsafe_allow_html=True)
    

def display_parsed_data(parsed_data,missing_fields):
    if not parsed_data:
        st.error("Error: No valid resume data to display")
        return
        # Process missing fields into structured format
    structured_missing = defaultdict(lambda: defaultdict(int))
    for path in missing_fields:
        # Preserve array indices for list items
        clean_path = re.sub(r'\[(\d+)\]', lambda m: f"[{m.group(1)}]", path)  # Keep indices for tracking multiple entries
        parts = clean_path.split('.', 1)
        top_field = parts[0]
        
        if len(parts) > 1:
            sub_field = parts[1]
            # Handle array indices in subfields (e.g., Education[0].Degree)
            if '[' in sub_field:
                field_parts = sub_field.split('[', 1)
                main_field = field_parts[0]
                structured_missing[top_field][main_field] += 1
            else:
                structured_missing[top_field][sub_field] += 1
        else:
            structured_missing[top_field]["_top"] += 1
            
    # Extract parsed data fields
    Full_Name = parsed_data.get("Name", "N/A")
    Email = parsed_data.get("Email", "N/A")
    Contacts = parsed_data.get('Phone_1', 'N/A')
    Address = parsed_data.get("Address", "N/A")
    LinkedIn = parsed_data.get("LinkedIn", "N/A")
    GitHub = parsed_data.get("GitHub", "N/A")
    Suggested_Resume_Category = parsed_data.get("Suggested_Resume_Category", "N/A")
    Applied_for_Profile = parsed_data.get("Applied_for_Profile", "N/A")
    Professional_Experience_in_Years = parsed_data.get("Professional_Experience_in_Years", "N/A")
    Highest_Education = parsed_data.get("Highest_Education", "N/A")
    Skills = parsed_data.get("Skills", [])
    Achievements = parsed_data.get("Achievements", ["N/A"])
    
    
    # References = parsed_data.get("References", [])
    Work_Experience = parsed_data.get("Work_Experience") or []

    # Initialize Professional_Experience_str as an empty list
    # Updated display logic in display_parsed_data() function
# Inside display_parsed_data()
    Work_Experience_str = []
    for job in Work_Experience:
        date_str = f"({job.get('Start_Date', 'N/A')} to {job.get('End_Date', 'N/A')})"
        job_entry = [
            f"{job.get('Job_Title', 'N/A')} at {job.get('Company', 'N/A')} {date_str}"
        ]
        
        # Always show projects section
        job_entry.append("<strong>Projects:</strong>")
        if job.get('Projects'):
            for project in job['Projects']:
                title = project.get('Project_Title', 'N/A')
                description = project.get('Description', 'N/A')
                job_entry.append(f"<strong>{title}</strong>: {description}")
        else:
            job_entry.append("N/A")
        
        Work_Experience_str.append("<br>".join(job_entry))
            # After Work Experience section
    
    # Ensure that Certifications is never empty and defaults to "N/A" if missing or empty
    Certifications = parsed_data.get("Certifications", ["N/A"])

    Education = parsed_data.get("Education", [])

    # In display_parsed_data() - Education section
    Education_str = []
    for edu in Education:
        raw_date = edu.get('Graduation_Date', 'N/A')
        date_display = raw_date if is_valid_date(raw_date) else "N/A"
        Education_str.append(
            f"{edu.get('Degree', 'N/A')} from {edu.get('University', 'N/A')} "
            f"(Graduated: {date_display})"
        )

    Suggested_Resume_Category = parsed_data.get("Suggested_Resume_Category", "N/A")
    
    Recommended_Additional_Skills = parsed_data.get("Recommended_Additional_Skills", [])
    


    # references_str = [
    #     f"{ref.get('Name', 'N/A')} ({ref.get('Designation', 'N/A')}) | "
    #     f"Email: {ref.get('Email', 'N/A')} | Phone: {ref.get('Phone', 'N/A')}"
    #     for ref in References
    # ] if References else ["N/A"]

    # Render data in containers using the function
    st.markdown(
        '''<div style='margin-top: 20px; text-align: center;'>
            <h3 style='color: #1d3557;'>Resume Analysis</h3>
        </div>''',
        unsafe_allow_html=True
    )
    st.markdown(f"<h6 style='font-size: 20px;'>Hi {Full_Name}! 😊</h6>", unsafe_allow_html=True)

    st.markdown(
        '''<div style='margin-top: 20px; text-align: center;'>
            <h5 style='color: #1d3557;'>Your Basic Information</h5>
        </div>''',
        unsafe_allow_html=True
    )
    
    
    st.markdown("""
        <style>
            .warning-text {
                font-size: 12px;
                color: red;
                margin-top: 5px !important; /* Reduce spacing */
            }
        </style>
        """, unsafe_allow_html=True)


    st.write("Email:", Email)
    if "Email" in structured_missing:
        if structured_missing["Email"].get("_top", 0) > 0:
            st.markdown('<div class="warning-text">⚠️ Must Include Email</div>', unsafe_allow_html=True)

    st.write("Contacts:", Contacts)
    if "Contacts" in structured_missing:
        if structured_missing["Contacts"].get("_top", 0) > 0:
            st.markdown('<div class="warning-text">⚠️ Must Include Contacts</div>', unsafe_allow_html=True)

    st.write("Address:", Address)
    if "Address" in structured_missing:
        if structured_missing["Address"].get("_top", 0) > 0:
            st.markdown('<div class="warning-text">⚠️ Must Include Address</div>', unsafe_allow_html=True)

    st.write("LinkedIn:", LinkedIn)  # Check for missing LinkedIn
    if "LinkedIn" in structured_missing:
        if structured_missing["LinkedIn"].get("_top", 0) > 0:
            st.markdown('<div style="color: red; margin-top: -20px;font-size: 12px;">⚠️ Include LinkedIn Profile URL</div>', unsafe_allow_html=True)
            
    st.write("GitHub:", GitHub)
    if "GitHub" in structured_missing:
        if structured_missing["GitHub"].get("_top", 0) > 0:
            st.markdown('<div style="color: red; margin-top: -20px;font-size: 12px;">⚠️ Include GitHub Profile URL</div>', unsafe_allow_html=True)

    display_in_container("Suggested_Resume_Category", Suggested_Resume_Category)
    if "Suggested_Resume_Category" in structured_missing:
        if structured_missing["Suggested_Resume_Category"].get("_top", 0) > 0:
            st.markdown(
                '<div class="warning-text">⚠️ Suggested Resume Category will be displayed when your resume is ATS compatible</div>',
                unsafe_allow_html=True
            )
            
    # Profile Applied For
    display_in_container("Profile Applied For", Applied_for_Profile)
    if "Applied_for_Profile" in structured_missing:
        if structured_missing["Applied_for_Profile"].get("_top", 0) > 0:
            st.markdown(
                '<div class="warning-text">⚠️ Your resume does not specify Target Job Profile</div>',
                unsafe_allow_html=True
            )
    
    # Display Highest Education as a single value

    display_in_container("Highest Education", Highest_Education)
    if "Highest_Education" in structured_missing:
        if structured_missing["Highest_Education"].get("_top", 0) > 0:
            st.markdown(
                '<div class="warning-text">⚠️ Include Education Field clearly </div>',
                unsafe_allow_html=True
            )
    
    # Display Education Details as a list
    display_in_container("Education ", Education_str)
    # After Education section
# Initialize variables with default values
    grad_missing = 0
    degree_missing = 0
    university_missing = 0

    if "Education" in structured_missing:
        # Count all instances across array entries
        grad_missing = sum([v for k,v in structured_missing["Education"].items() if "Graduation_Date" in k])
        degree_missing = sum([v for k,v in structured_missing["Education"].items() if "Degree" in k])
        university_missing = sum([v for k,v in structured_missing["Education"].items() if "University" in k])

    # Now check each variable
    total_edu_missing = grad_missing + degree_missing + university_missing
    if total_edu_missing > 0:
        st.markdown(f'<div class="warning-text">⚠️ Education Section Missing {total_edu_missing} Entries</div>', unsafe_allow_html=True)
        if grad_missing > 0:
            msg = f"• Graduation Date ({grad_missing} missing)"
            st.markdown(f'<div class="warning-text" style="margin-left: 20px;">{msg}</div>', unsafe_allow_html=True)
        if degree_missing > 0:
            msg = f"• Degree ({degree_missing} missing)"
            st.markdown(f'<div class="warning-text" style="margin-left: 20px;">{msg}</div>', unsafe_allow_html=True)
        if university_missing > 0:
            msg = f"• University ({university_missing} missing)"
            st.markdown(f'<div class="warning-text" style="margin-left: 20px;">{msg}</div>', unsafe_allow_html=True)
    display_in_container("Experience in Years", Professional_Experience_in_Years)
    if "Professional_Experience_in_Years" in structured_missing:
        if structured_missing["Professional_Experience_in_Years"].get("_top", 0) > 0:
            st.markdown(
                '<div class="warning-text">⚠️ Add Years of Experience in Work Experience</div>',
                unsafe_allow_html=True
            )

    # Display Skills as a list
    display_in_container("Skills", Skills)
    if "Skills" in structured_missing:
        total_skills_issues = sum(structured_missing["Skills"].values())
        if total_skills_issues > 0:
            msg = "⚠️ Improve Skills Section"
            if total_skills_issues > 1:
                msg += f" ({total_skills_issues} issues found)"
            st.markdown(
                f'<div class="warning-text">{msg}</div>',
                unsafe_allow_html=True
            )
    # Inside display_parsed_data() function, after processing Work_Experience_str
# Add this line to actually display the work experience container
    display_in_container("Work Experience", Work_Experience_str)
    if "Work_Experience" in structured_missing:
        projects_missing = structured_missing["Work_Experience"].get("Projects", 0)
        dates_missing = (
            structured_missing["Work_Experience"].get("Start_Date", 0) +
            structured_missing["Work_Experience"].get("End_Date", 0)
        )
        if projects_missing > 0:
            msg = "⚠️ Include Project Details"
            if projects_missing > 1:
                msg += f" ({projects_missing} entries)"
            st.markdown(f'<div class="warning-text">{msg}</div>',
                        unsafe_allow_html=True)
        if dates_missing > 0:
            msg = "⚠️ Include Job Dates"
            st.markdown(f'<div class="warning-text">{msg}</div>',
                        unsafe_allow_html=True)
    # Display Certifications as a list
    # After Certifications section
    display_in_container("Certifications", Certifications)
    if "Certifications" in structured_missing:
        cert_missing = structured_missing["Certifications"].get("_top", 0)
        if cert_missing > 0:
            msg = "⚠️ Include Certifications"
            if cert_missing > 1:
                msg += f" ({cert_missing} entries)"
            st.markdown(f'<div class="warning-text">{msg}</div>', 
                        unsafe_allow_html=True)
    display_in_container("Achievements", Achievements)
    if "Achievements" in structured_missing:
        achieve_missing = structured_missing["Achievements"].get("_top", 0)
        if achieve_missing > 0:
            st.markdown('<div class="warning-text">⚠️ Include Achievements</div>',
                        unsafe_allow_html=True)
    # Display Recommended Additional Skills as a list
    display_in_container(f"Recommended Additional Skills for {Suggested_Resume_Category}", Recommended_Additional_Skills)
    st.caption("Adding these skills to resume will boost your chance of getting a job")

output
Resume Analysis
Hi Bright Kyeremeh! 😊
Your Basic Information
Email: mrbriit@gmail.com

Contacts: +919467891831

Address: Pune, India

LinkedIn: https://www.linkedin.com/in/mrbriit/

GitHub: N/A

⚠️ Include GitHub Profile URL
Suggested_Resume_Category
Data Scientist
Profile Applied For
Data Scientist
Highest Education
MBA Data Science
Education
MBA Data Science from MIT ADT University (Graduated: N/A)
Bachelor Of Education(Mathematics) from University Of Cape Coast (Graduated: N/A)
Experience in Years
5+
Skills
Data Science
Python
Machine Learning
Deep Learning
Artificial Intelligence
Chatbot Design
Natural Language Processing
Computer Vision
Statistics
SQL
Excel
Web Scraping
Data Analysis
Data Mining
Research Methodologies
Report Writing
Data Visualization
TensorFlow
Pandas
Numpy
Seaborn
Selenium
Beautiful Soup
Scrapy
Flask
MySQL
AWS
Google Cloud
Work Experience
Data And Research Assistant at Accreditation Council for Business Schools and Programs(ACBSP) (Jun 2015 to Jul 2017)
Projects:
N/A
Product Manager Intern at Synacor (Aug 2020 to Jan 2021)
Projects:
N/A: Helped to integrate A.I. in existing products
Technology Consultant Intern at Deloitte (May 2020 to Jul 2020)
Projects:
N/A: Leveraged large datasets from various sources at Deloitte, use the skills of Data Analysis, Natural Language Processing and Visualisation to analyze the range of technologies currently being used across the financial services sector and take into consideration emerging technologies for implementing an online banking solution.
Go-To-Market Strategist Intern at Microsoft (Mar 2020 to May 2020)
Projects:
N/A: Analysing the economics of a product using strategic Go-To-Market strategy to achieve a high product market fit.
Data Scientist Intern at ANZ (Jan 2020 to Mar 2020)
Projects:
N/A: Leverage large dataset of over 100 customers over a period of time: analyze, visualise and build regression models to help predict behaviour of future customers regarding purchases, recurring transactions, and salary transactions.
Founder/Information Technologist at Total Data Science (Aug 2020 to Present)
Projects:
N/A
UDEMY Data Science Instructor at Udemy (Aug 2020 to Present)
Projects:
N/A
Certifications
IBM Certified Data Scientist
Delhi Institute Of Digital Marketing: Professional Certificate in Social Media & Digital Marketing
FutureLearn Certificate in Research Methodology
FutureLearn Certificate in Developing Research Report
FutureLearn Certificate in Writing a Research Proposal
Certified Ministry of Education, Ghana, High School Mathematics Instructor
Coursera: Data Structures & Algorithm, Operating System Design
Achievements
Top 3 Percentile of the class (MIT ADT University)
GPA: 8.35/10 (MIT ADT University)
Top 5 Percentile of the class (University Of Cape Coast)
GPA: 3.2/4.0 (University Of Cape Coast)
10 Courses | 2000+ Global Student base (Udemy)
Recommended Additional Skills for Data Scientist
Cloud Computing (AWS, Azure, GCP)
Big Data Technologies (Spark, Hadoop)
Database Management (MongoDB, PostgreSQL)
Model Deployment
Data Storytelling
Adding these skills to resume will boost your chance of getting a job

⚠️ Found 10 missing fields.
the markdown for other feilds such as education dissapeared.
home.py
from libraries import *
from ats import convert_docx_to_pdf
import streamlit_authenticator as stauth
from PyPDF2 import PdfReader

from collections import defaultdict 
# In home.py - Update import statement
from json_file import resume_details, display_parsed_data, count_na 
from Courses import ds_course,web_course,android_course,ios_course,uiux_course,resume_videos,interview_videos

uploaded_resume_dir = os.path.abspath('./Uploaded_Resumes')
    # docx_resume_path = os.path.abspath('./Uploaded_docx_resume') # The path of the uploaded file (DOCX or PDF)
    # Ensure the directory exists
if not os.path.exists(uploaded_resume_dir):
        os.makedirs(uploaded_resume_dir)

    # Function to display the resume PDF
def show_resume(uploaded_resume_path):
    try:
        with open(uploaded_resume_path, "rb") as f:
            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
            pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
            st.markdown(pdf_display, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"Error displaying resume: {e}")
        
        
def extract_text_from_pdf(uploaded_resume_path):
    try:
        with open(uploaded_resume_path, "rb") as file:
            reader = PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() 
                #get resume details from model
            response=resume_details(text)
            return response
    except Exception as e:
        st.error(f"Error extracting text from PDF: {e}")
        return None
def course_recommender(course_list):
    st.subheader("Courses and  Certificates Recommendation")
    c=0 
    rec_course=[]
    no_of_reco=st.slider("choose no of courses you want to be recommended:", 1,5,10)
    random.shuffle(course_list)
    for c_name,c_link in course_list:
        c+=1
        st.markdown(f"({c}) [{c_name}]({c_link})")
        rec_course.append(c_name)
        if c==no_of_reco:
            break
        
        return rec_course

def run():
    
    components()

        
    st.markdown(
            '''<div style='margin-top: 20px; text-align: center;'>
                <h5 style='color: #1d3557;'>Upload your Resume</h5>
            </div>''',
            unsafe_allow_html=True
        )

    # Initialize session state
    if 'prev_upload' not in st.session_state:
        st.session_state.update({
            'prev_upload': None,
            'parsed_data': None,
            'na_count': 0
        })

    file_uploaded = st.file_uploader(" ", type=["pdf", "docx"])
    
    # Detect new upload and reset state
    if file_uploaded != st.session_state.prev_upload:
        st.session_state.prev_upload = file_uploaded
        st.session_state.parsed_data = None
        st.session_state.na_count = 0
        st.rerun()  # Clear previous outputs

        
    if file_uploaded is not None:
        # Save the uploaded file to the appropriate directory
        file_extension = file_uploaded.name.split('.')[-1].lower()
        placeholder = st.empty()
        # Determine the path for the file
        uploaded_resume_path = os.path.join(uploaded_resume_dir, file_uploaded.name)
            # Save the PDF directly
        with open(uploaded_resume_path, "wb") as f:
            f.write(file_uploaded.getbuffer())
            
        if file_extension == "pdf":
            placeholder.success("Resume uploaded successfully!")
            time.sleep(4)
            placeholder.empty()
            show_resume(uploaded_resume_path)
        elif file_extension == "docx":
            # Save the DOCX file temporarily, convert it to PDF, and save the PDF
            converted_pdf_path = convert_docx_to_pdf(uploaded_resume_path)
            if converted_pdf_path:
                uploaded_resume_path = converted_pdf_path  # Update the path to the converted PDF
                st.success("DOCX converted to PDF successfully!")
            show_resume(uploaded_resume_path)
        else:
                st.error("DOCX conversion failed.") 
                

        with st.spinner("Extracting and parsing resume..."):
            resume_text = extract_text_from_pdf(uploaded_resume_path)
            if resume_text:
                st.session_state.parsed_data = resume_details(resume_text)
        if st.session_state.parsed_data:
            na_count, na_paths = count_na(st.session_state.parsed_data)
            display_parsed_data(st.session_state.parsed_data, missing_fields=na_paths)
            # Remove the old missing fields summary code here
            
        na_count, na_paths = count_na(st.session_state.parsed_data)
                        
        # In display_parsed_data() function
        clean_paths = [
            re.sub(r'\[\d+\]', '', p)  # Remove array indices
            .title()  # Remove .replace("_", " ")
            for p in na_paths
        ]

                # Group by parent category
        field_counts = defaultdict(int)
        category_fields = defaultdict(set)
        standalone_fields = set()

        for path in clean_paths:
            if '.' in path:
                category, field = path.split('.', 1)
                category_fields[category].add(field)
                field_counts[f"{category}.{field}"] += 1
            else:
                standalone_fields.add(path)
                field_counts[path] += 1

        # Build display items


        # In home.py, after counting NA
        st.markdown(f"""
            <div style="margin-top: 20px; padding: 10px; background-color: #ffe6e6; border-radius: 25px; text-align: center;">
                ⚠️ Found {na_count} missing fields.
            </div>
        """, unsafe_allow_html=True)

#         # Call the run function to execute the app
if __name__ == "__main__":
        run()
ats.py
from libraries import *
def convert_docx_to_pdf(docx_resume_path):
        
    if docx_resume_path.endswith(".docx"): 
        try:
                # Initialize COM threading model
            pythoncom.CoInitialize()  # COM allows different software components (written in different languages) to communicate with each other.

                # Define paths for DOCX and the output PDF
            uploaded_resume_path = os.path.splitext(docx_resume_path)[0] + ".pdf"  

                # Initialize Word COM object
            word = comtypes.client.CreateObject("Word.Application")
            word.Visible = False  # Run Word in the background

                # Open DOCX and save as PDF
            in_file = word.Documents.Open(docx_resume_path)
            in_file.SaveAs(uploaded_resume_path, FileFormat=17)  # PDF format constant
            in_file.Close()
            word.Quit()

        except Exception as e:
                st.error(f"An error occurred during conversion: {e}")
                return None
        finally:
                # Uninitialize COM after usage
                pythoncom.CoUninitialize()

        return uploaded_resume_path  # Return the path to the converted PDF file
def is_valid_date(date_str):
    """Check if date matches mm/yyyy or Month YYYY format"""
    if not isinstance(date_str, str):
        return False
    # Check for Month YYYY format (e.g., "May 2023")
    if len(date_str.split()) == 2:
        month, year = date_str.split()
        if month.lower() in ["january", "february", "march", "april", "may", "june",
                        "july", "august", "september", "october", "november", "december"]:
            return year.isdigit() and len(year) == 4
        
    # Check for mm/yyyy format (e.g., "05/2023")
    if len(date_str.split('/')) == 2:
        month, year = date_str.split('/')
        return month.isdigit() and 1 <= int(month) <= 12 and year.isdigit() and len(year) == 4
    
    if date_str in ["Present", "N/A"]:
        return True
    
def _tracker(data, missing, path="", strict=False):
    # Keep existing logic but improve value validation
    if isinstance(data, dict):
        for key, value in data.items():
            new_path = f"{path}.{key}" if path else key
            if isinstance(value, (dict, list)):
                _tracker(value, missing, new_path, strict)
            else:
                # Enhanced validation for date-like fields
                if key.lower() == "graduation_date" and not is_valid_date(str(value)):
                    missing.append(new_path)
                elif str(value).strip().upper() in ["N/A", "NA", "NONE", ""]:
                    missing.append(new_path)
        if not data and path:
            missing.append(path)
    elif isinstance(data, list):
        if not data and path:
            missing.append(path)
        for idx, item in enumerate(data):
            new_path = f"{path}[{idx}]" if path else f"[{idx}]"
            _tracker(item, missing, new_path, strict)